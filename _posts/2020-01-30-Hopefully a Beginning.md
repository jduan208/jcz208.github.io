# Hopefully a Beginning

This blog will likely be a jumble of half-fleshed out thoughts, the occasionally well-formed thought (it's anyone's guess as to whether it'll be anywhere near epistemologically sound), and updates on my shiny new project, conceived of as of today.

I met with my math professor yesterday and, because she's God's gift to this Earth, she listened to my griping and uncertainty about what to actually do with my sack of shit self and extended a hand. We brainstormed for bit, and I've got the skeleton of a future idea that may have some sort of real world impact... maybe. Because of my interest in AI alignment, I'd been kicking around an idea similar to this for a while, but without an external push I never actually sat down and codified exactly what I wanted to achieve, so here it is:

I want to create an intelligent agent that can model and predict my preferences given feedback. I also want it to be able to spit out a coherent representation of that model of me in a way that I can understand (e.g. utility function with preferences/metapreferences/global preferences, a graph, or some other intelligible format). As for what specific preferences I want it to model, my ideas so far have ranged from as specific as "what classes should I take next semester at what times" (although that seems more social media/ad algorithm-esque to me to feel totally right) to "modeling the difference between my stated values and preferences and my actual values and preferences based on my actions and selected inner thoughts." As much as I'd like to tackle a problem with the scope of the latter, I'm not quite sure I'm there yet, but I'll give it some thought.

The problem is, I don't even really know where to start. The idea of an intelligent agent learning preferences from another (ir)rational being is loosely taken from inverse reinforcement learning, but seeing as how I don't even exactly know what that is, I'm sure to find a bunch of open problems and implementation-related obstacles here. I'm also a lazy sack of shit, but hopefully the social pressure of writing on this blog (to an audience of one: me) and my professor checking in on me will keep me going a little longer than average. On top of that, I don't want it to realize that making me more predictable is the best way to minimize its surprise in its model of me, as we've seen in social media algorithms. 

All of that being said, the most likely killer will be me trying to learn everything without getting my hands into the mud. I'll be monitoring myself for that, and hopefully, an agent that I've designed will be able to monitor me and my hypocrisy as well. 

As for existing models, thoughts, and implementations, I haven't even begun to look at the literature yet, so that may just be a first step. I've taken some inspiration and ideas from Stuart Armstrong, but I'll be looking into what others have done and what others have thought soon enough.

This blurred map of fuzzy thoughts in my head is all I have. I'll be doing some thinking, writing, and reading (in that order; otherwise, I'll read everything and never get started) to clear up my own thoughts and motivation for this project. 

I'll tentatively say that I'll keep my blog updated on this project's status around once a week to once every other week, with other posts interspersed in between. 
